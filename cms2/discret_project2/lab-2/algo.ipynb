{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratory work #2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of the performance of algorithms on certain text data of different sizes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Huffman's algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм Гаффмана\n",
    "Клас містить два методи:\n",
    "\n",
    "encode: закодовує повідомлення\n",
    "Спочатку створює словник з різних символів і рахує, скільки разів кожен з них зустрічався в повідомленні. Далі на основі цього рахуються ймовірності, з якими зустрічається кожен символ. Потім з цього словника робимо ліст тюплів. І сортуємо його так, щоб спочатку були символи з найменшою ймовірністю. Після цього об'єднюємо перші два елементи в один, додаємо '1' та '0' до їх кодів відповідно (0 – до того, що більше), видаляємо ці елементи зі списку, додаємо туди новий елемент(його ймовірність – сума попередніх двох) і знову сортуємо наш список. Повторюємо це, поки не залишиться один елемент в списку. Тоді у нас вже є в словник кодів. Закодовуємо кожен символ повідомлення та повертаємо результат.\n",
    "\n",
    "decode: розкодовує повідомлення\n",
    "Маючи словник кодів розкодовуємо закодоване повідомлення.\n",
    "Считуємо символ, якщо він не відповідає жодному коду в словнику, считуємо наступний. Коли код є в словнику, додаємо розкодований символ до розкодованого повідомлення. І обрізаємо закодоване повідомлення до першого ще не прочитаного символу. Повторюємо все це, поки не дійдемо до кінця і не розкодуємо все повідомлення, після цього повертаємо результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module implements Huffman algorithm\n",
    "\"\"\"\n",
    "from time import time\n",
    "class Huffman:\n",
    "    \"\"\"\n",
    "    this class allows to use Huffman algorithm for encoding and decoding\n",
    "    \"\"\"\n",
    "    def __init__(self, message:str, res_dict={})-> None:\n",
    "        \"\"\"\n",
    "        message - message, that should be encoded or decoded\n",
    "        res_dict - dictionary with keys for encoding and decoding\n",
    "        \"\"\"\n",
    "        self.message = message\n",
    "        self.res_dict = res_dict\n",
    "    def encode(self, message):\n",
    "        \"\"\"\n",
    "        encode the message using Huffman algorithm\n",
    "        \"\"\"\n",
    "        self.message = message\n",
    "        freq_dict = {}\n",
    "        length = len(self.message)\n",
    "\n",
    "        for elem in self.message:\n",
    "            if elem not in freq_dict:\n",
    "                freq_dict[elem] = 1\n",
    "            else:\n",
    "                freq_dict[elem] += 1\n",
    "\n",
    "        for elem in freq_dict:\n",
    "            freq_dict[elem] /= length\n",
    "            self.res_dict[elem] = ''\n",
    "        alphabet = sorted(list(freq_dict.items()), key=lambda x:x[1])\n",
    "        if len(alphabet) == 1:\n",
    "            self.res_dict[alphabet[0][0]] = '1'\n",
    "        else:\n",
    "            while len(alphabet) > 1:\n",
    "                new_el = alphabet[0][0] + alphabet[1][0]\n",
    "                new_val = alphabet[0][1] + alphabet[1][1]\n",
    "                for i in alphabet[0][0]:\n",
    "                    self.res_dict[i] = '1' + self.res_dict[i]\n",
    "\n",
    "                for i in alphabet[1][0]:\n",
    "                    self.res_dict[i] = '0' + self.res_dict[i]\n",
    "\n",
    "                alphabet = alphabet[2:]\n",
    "                alphabet.append((new_el, new_val))\n",
    "                alphabet = sorted(alphabet, key=lambda x: x[1])\n",
    "\n",
    "        encoded_mes = ''\n",
    "        for elem in self.message:\n",
    "            encoded_mes += self.res_dict[elem]\n",
    "        return encoded_mes\n",
    "\n",
    "\n",
    "    def decode(self, message):\n",
    "        \"\"\"\n",
    "        decode the message using Huffman algorithm\n",
    "        \"\"\"\n",
    "       # message = self.message\n",
    "        dictionary = {v: k for k, v in self.res_dict.items()}\n",
    "        decoded_mes = ''\n",
    "        i = 1\n",
    "\n",
    "        while (message != '') and (i <= len(message)):\n",
    "            if message[:i] in dictionary:\n",
    "                decoded_mes += dictionary[message[:i]]\n",
    "                message = message[i:]\n",
    "                i = 1\n",
    "            else:\n",
    "                i += 1\n",
    "        return decoded_mes\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LZW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цей код реалізує алгоритм LZW для кодування та декодування повідомлень. \n",
    "Клас LZW має метод encode, який приймає повідомлення та повертає закодоване повідомлення як список цілих чисел(які відповідають кодам в словнику). Метод decode приймає закодоване повідомлення та повертає розкодоване повідомлення у вигляді рядка.\n",
    "\n",
    "У процесі кодування створюється словник усіх символів у повідомленні, призначаються їм коди (починаючи з 0), а потім сканується повідомлення, щоб знайти найдовший підрядок, який уже є в словнику. Коли знайдено новий підрядок, йому присвоюється новий код і додається до словника. Тоді закодоване повідомлення є послідовністю кодів цих підрядків.\n",
    "\n",
    "Процес декодування працює шляхом створення того самого словника символів і кодів, який використовувався для кодування. Ми зчитуємо послідовність кодів із закодованого повідомлення та використовуємо словник для перекладу кожного коду назад у відповідний символ. Коли зустрічається код, якого немає в словнику, вважається, що це код нового символу, тоді ми починаємо додавати в словник коди так, ніби ми розкодовуємо те повідомлення, яке є на даний момент. Потім знову перевіряємо, чи код є в словнику, якщо все ще немає, то вважаємо, що наступний символ збігається з тим, на якому поки що зупинились(починаючи з якого ми ще не розкодували)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "class LZW:\n",
    "    \"\"\"\n",
    "    this class allows to use LZW algorithm for encoding and decoding\n",
    "    \"\"\"\n",
    "    def __init__(self, message, code_dict={}):\n",
    "        \"\"\"\n",
    "        init method\n",
    "        message - message that has to be encoded or decoded\n",
    "        code_dict - start dictionary\n",
    "        \"\"\"\n",
    "        self.message = message\n",
    "        self.code_dict = code_dict\n",
    "\n",
    "    def encode(self, message):\n",
    "        \"\"\"\n",
    "        encode the message using lzw algorithm\n",
    "        \"\"\"\n",
    "        self.message = message\n",
    "        code = 0\n",
    "        for elem in self.message:\n",
    "            if elem not in self.code_dict:\n",
    "                self.code_dict[elem] = code\n",
    "                code += 1\n",
    "        encoded_mes = ''\n",
    "        message = self.message\n",
    "        j = 0\n",
    "        cur_symbol = ''\n",
    "        cod_dict = self.code_dict.copy()\n",
    "        length = 1\n",
    "        while j+length < len(message):\n",
    "            cur_symbol = message[j:j+length]\n",
    "            next_symbol = message[j+length]\n",
    "            line = cur_symbol + next_symbol\n",
    "            length += 1\n",
    "            if line not in cod_dict:\n",
    "                cod_dict[line] = code\n",
    "                code += 1\n",
    "\n",
    "                encoded_mes += str(cod_dict[cur_symbol])+','\n",
    "                length = 1\n",
    "                j += len(line) - 1\n",
    "\n",
    "        if length == 1:\n",
    "            encoded_mes += str(cod_dict[message[-1]])\n",
    "        else:\n",
    "            if j + length == len(message):\n",
    "                encoded_mes += str(cod_dict[cur_symbol]) + ',' + str(cod_dict[message[-1]])\n",
    "\n",
    "        return encoded_mes\n",
    "\n",
    "    def decode(self, message):\n",
    "        \"\"\"\n",
    "        decode the message using lzw algorithm\n",
    "        \"\"\"\n",
    "        self.message = message\n",
    "        cod_dict1 = self.code_dict.copy()\n",
    "        cod_dict2 = cod_dict1.copy()\n",
    "\n",
    "        cod_dict2 = {v: k for k, v in cod_dict2.items()}\n",
    "\n",
    "        encoded = self.message.split(',')\n",
    "        decoded_mes = ''\n",
    "        i = 0\n",
    "        index = 0\n",
    "        code = len(cod_dict1)\n",
    "\n",
    "        while i < len(encoded):\n",
    "            if int(encoded[i]) in cod_dict2:\n",
    "                decoded_mes += cod_dict2[int(encoded[i])]\n",
    "                i += 1\n",
    "            else:\n",
    "                length = 1\n",
    "                cur_symbol = ''\n",
    "                flag = False\n",
    "                while index+length < len(decoded_mes):\n",
    "                    flag = True\n",
    "                    cur_symbol = decoded_mes[index:index+length]\n",
    "                    next_symbol = decoded_mes[index+length]\n",
    "                    line = cur_symbol + next_symbol\n",
    "                    length += 1\n",
    "                    if line not in cod_dict1:\n",
    "                        cod_dict1[line] = code\n",
    "                        cod_dict2[code] = line\n",
    "                        code += 1\n",
    "                        length = 1\n",
    "                        index += len(line) - 1\n",
    "\n",
    "                if int(encoded[i]) not in cod_dict2:\n",
    "                    if flag:\n",
    "                        line = decoded_mes[index:]\n",
    "                        line += line[0]\n",
    "\n",
    "                    else:\n",
    "                        line = decoded_mes[-1] + decoded_mes[-1]\n",
    "\n",
    "                    cod_dict1[line] = code\n",
    "                    cod_dict2[code] = line\n",
    "                    code += 1\n",
    "                    index += len(line) - 1\n",
    "                    length = 1\n",
    "\n",
    "        return decoded_mes\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LZ77"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цей код є реалізацією алгоритму стиснення даних LZ77.\n",
    "\n",
    "Клас LZ77 містить два методи - compress і decompress - які використовують алгоритм для стиснення та розпакування даних відповідно.\n",
    "\n",
    "У методі compress текстовий файл зчитується в змінну text. Далі, передана рядок кодується у байти, тобто перетворюється на послідовність чисел, які можуть бути збережені в комп'ютері. Метод знаходить збіги між даними, які вже були зчитані, і даними, які ще мають бути зчитані. Якщо збіг знайдено, метод створює трикутник (offset, length, next_char), де offset - це позиція першого збігу в попередньому тексті, length - довжина збігу, а next_char - наступний символ, що йде після збігу. Якщо збіг не знайдено, метод додає одиничний трикутник (0, 0, next_char), де next_char - наступний символ, що має бути зчитаний. Після створення всіх трикутників, метод повертає їх як список.\n",
    "\n",
    "У методі decompress метод приймає стиснуті дані у вигляді списку трикутників (offset, length, next_char), які були створені методом compress. Метод проходиться по списку трикутників і розкодовує їх, створюючи розгорнутий текст. Якщо length більше нуля, то в розгорнутий текст додається довжина символів, які повторюються від позиції (len(output) - offset) до length. Інакше, якщо length дорівнює нулю, то в розгорнутий текст додається наступний символ, що має бути декодований."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LZ77:\n",
    "    \"\"\"\n",
    "    This class allows you to use the LZ77 algorithmto compress text and decrypt it.\n",
    "    >>> lz = LZ77()\n",
    "    \"\"\"\n",
    "    def __init__(self, window_size=64, buffer_size=16):\n",
    "        \"\"\"\n",
    "        Constructor of the class\n",
    "        The window_size parameter specifies the size of the search window\n",
    "        and the buffer_size parameter specifies the size of the input view buffer.\n",
    "        (By default: window_size=1024, buffer_size=64)\n",
    "        >>> lz = LZ77(2048, 32)\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.buffer_size = buffer_size\n",
    "\n",
    "    def compress(self, string):\n",
    "        \"\"\"\n",
    "        According to the LZ77 compression algorithm, it compresses\n",
    "        the file and returns a compact encrypted text in the form\n",
    "        of tuples of the type (offset, length, next_char)\n",
    "        >>> mini_text = \"asdasdasdasdasd\"\n",
    "        >>> lz.compress(mini_text)\n",
    "        \"\"\"\n",
    "        data, output, iter = string.encode(), [], 0\n",
    "        while iter < len(data):\n",
    "            best_match = (0, 0)\n",
    "            search_start = max(0, iter - self.window_size)\n",
    "            for j in range(search_start, iter):\n",
    "                length = 0\n",
    "                while iter + length < len(data) and data[j + length] == data[iter + length]:\n",
    "                    length += 1\n",
    "                    if length > best_match[1]:\n",
    "                        best_match = (iter - j, length)\n",
    "            if best_match[1] > 0:\n",
    "                try:\n",
    "                    output.append((best_match[0], best_match[1], data[iter + best_match[1]]))\n",
    "                except IndexError:\n",
    "                    output.append((best_match[0], best_match[1], 0))\n",
    "                iter += best_match[1] + 1\n",
    "            else:\n",
    "                output.append((0, 0, data[iter]))\n",
    "                iter += 1\n",
    "        return output\n",
    "\n",
    "    def decompress(self, compressed_data):\n",
    "        \"\"\"\n",
    "        The decompress method takes a compressed sequence of data\n",
    "        as a list of tuples and returns an expanded string. It\n",
    "        restores the original data using information from the\n",
    "        tuples obtained from the compress method.\n",
    "        >>> lz.decompress([(0, 0, 'a'), (0, 0, 's'), (0, 0, 'd'), (3, 12, '')])\n",
    "        'asdasdasdasdasd'\n",
    "        \"\"\"\n",
    "        output = b\"\"\n",
    "        for triple in compressed_data:\n",
    "            if triple[1] > 0:\n",
    "                start = len(output) - triple[0]\n",
    "                for i in range(triple[1]):\n",
    "                    output += bytes([output[start + i]])\n",
    "            output += bytes([triple[2]])\n",
    "        if output[-1] == 0:\n",
    "            return output[:-1].decode()# becouse 0 at end\n",
    "        else: return output[:].decode()# becouse 0 at end\n",
    "lz = LZ77()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Deflate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Клас LZ77HuffmanEncoder містить методи для стиснення та розстиснення рядків даних за допомогою комбінації алгоритмів LZ77 та Хаффмана.\n",
    "\n",
    "Конструктор класу приймає два аргументи - розмір вікна (яке визначає максимальну довжину повторень) та розмір буферу перегляду (який визначає кількість символів, які можуть бути переглянуті наступним символом для пошуку повторень).\n",
    "\n",
    "Метод encode виконує стиснення рядка даних, переданого як аргумент data. Для кожного символа у рядку data, метод шукає найдовше повторення у вікні та буфері перегляду. Якщо повторення не знайдено, символ кодується однобітовим значенням 0 та його ASCII-кодом. Якщо повторення знайдено, символ кодується двобітовим значенням 1, яке містить довжину повторення та зміщення на початок повторення у вікні. Кодований бітовий рядок піддається кодуванню Хаффмана, що дозволяє позбутися зайвих бітів та скоротити розмір результуючого рядка даних. Метод повертає стиснутий рядок даних.\n",
    "\n",
    "Метод find_longest_match приймає рядок даних та позицію в рядку, починаючи з якої відбуватиметься пошук найдовшого повторення. Метод повертає кортеж, що містить найдовше повторення та зміщення на початок повторення у вікні.\n",
    "\n",
    "Метод build_huffman_tree будує таблицю Хаффмана за заданою таблицею частот символів.\n",
    "\n",
    "Метод apply_huffman_encoding застосовує кодування Хаффмана до бітового рядка.\n",
    "\n",
    "Метод decode виконує розстиснення рядка даних, закодованого за допомогою методу encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class LZ77HuffmanEncoder:\n",
    "    def __init__(self, window_size = 64, lookahead_buffer_size=16):\n",
    "        self.window_size = window_size\n",
    "        self.lookahead_buffer_size = lookahead_buffer_size\n",
    "        self.bitstream = \"\"\n",
    "        self.huffman_table = {}\n",
    "\n",
    "    def encode(self, data: str) -> str:\n",
    "        index = 0\n",
    "        while index < len(data):\n",
    "            match_length, match_offset = self.find_longest_match(data, index)\n",
    "            if match_length == 0:\n",
    "                self.bitstream += \"0\" + bin(ord(data[index]))[2:].zfill(8)\n",
    "                index += 1\n",
    "            else:\n",
    "                self.bitstream += \"1\" + bin(match_length)[2:].zfill(4) + bin(match_offset)[2:].zfill(12)\n",
    "                index += match_length\n",
    "\n",
    "        self.huffman_table = {}\n",
    "        for char in set(self.bitstream):\n",
    "            self.huffman_table[char] = self.bitstream.count(char) / len(self.bitstream)\n",
    "        self.huffman_table = self.build_huffman_tree(self.huffman_table)\n",
    "        self.bitstream = self.apply_huffman_encoding(self.bitstream, self.huffman_table)\n",
    "\n",
    "        return self.bitstream\n",
    "\n",
    "    def find_longest_match(self, data: str, index: int) -> tuple:\n",
    "        best_match_length = 0\n",
    "        best_match_offset = 0\n",
    "\n",
    "        window_start = max(0, index - self.window_size)\n",
    "        buffer_end = min(len(data), index + self.lookahead_buffer_size)\n",
    "\n",
    "        for i in range(index - window_start, 0, -1):\n",
    "            for j in range(index, buffer_end):\n",
    "                if data[window_start+i-1] != data[j]:\n",
    "                    break\n",
    "                elif j - index + 1 > best_match_length:\n",
    "                    best_match_length = j - index + 1\n",
    "                    best_match_offset = i - 1\n",
    "\n",
    "        return (best_match_length, best_match_offset)\n",
    "\n",
    "    def build_huffman_tree(self, freq_dict):\n",
    "        heap = [[freq, [char, \"\"]] for char, freq in freq_dict.items()]\n",
    "        heapq.heapify(heap)\n",
    "\n",
    "        while len(heap) > 1:\n",
    "            low_freq_pair = heapq.heappop(heap)\n",
    "            high_freq_pair = heapq.heappop(heap)\n",
    "            for pair in low_freq_pair[1:]:\n",
    "                pair[1] = '0' + pair[1]\n",
    "            for pair in high_freq_pair[1:]:\n",
    "                pair[1] = '1' + pair[1]\n",
    "            heapq.heappush(heap, [low_freq_pair[0] + high_freq_pair[0]] + low_freq_pair[1:] + high_freq_pair[1:])\n",
    "\n",
    "        huffman_tree = dict(sorted(heapq.heappop(heap)[1:], key=lambda p: (len(p[-1]), p)))\n",
    "        return huffman_tree\n",
    "\n",
    "    def apply_huffman_encoding(self, bitstream, huffman_table):\n",
    "        encoded = \"\"\n",
    "        for char in bitstream:\n",
    "            encoded += huffman_table[char]\n",
    "        return encoded\n",
    "\n",
    "    def decode(self, data: str) -> str:\n",
    "        # Decode the bitstream using the Huffman table\n",
    "        huffman_dict = dict((v, k) for k, v in self.huffman_table.items())\n",
    "        bitstream = \"\"\n",
    "        output_string = \"\"\n",
    "        index = 0\n",
    "        while index < len(data):\n",
    "            bitstream += data[index]\n",
    "            if bitstream in huffman_dict:\n",
    "                output_string += huffman_dict[bitstream]\n",
    "                bitstream = \"\"\n",
    "            index += 1\n",
    "\n",
    "        # Decompress the LZ77 encoded data\n",
    "        decoded_string = \"\"\n",
    "        index = 0\n",
    "        while index < len(output_string):\n",
    "            if output_string[index] == \"0\":\n",
    "                decoded_char = chr(int(output_string[index+1:index+9], 2))\n",
    "                decoded_string += decoded_char\n",
    "                index += 9\n",
    "            else:\n",
    "                match_length = int(output_string[index+1:index+5], 2)\n",
    "                match_offset = int(output_string[index+5:index+17], 2)\n",
    "                decoded_string += decoded_string[-match_offset:][:match_length]\n",
    "                index += 17\n",
    "\n",
    "        return decoded_string\n",
    "LZ77Huffman = LZ77HuffmanEncoder()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the serviceability of algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m enc_mes \u001b[39m=\u001b[39m lzw\u001b[39m.\u001b[39mencode(mini_text)\n\u001b[0;32m     12\u001b[0m dec_mes \u001b[39m=\u001b[39m lzw\u001b[39m.\u001b[39mdecode(enc_mes)\n\u001b[1;32m---> 13\u001b[0m \u001b[39massert\u001b[39;00m dec_mes \u001b[39m==\u001b[39m mini_text\n\u001b[0;32m     16\u001b[0m \u001b[39m# Try LZ77\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# lz = LZ77()\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m# compressed = lz.compress(mini_text)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39m# Try Deflate\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39m# я напишу\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mini_text = \"Hello world\"\n",
    "\n",
    "# Try Huffman's algorithm\n",
    "huffman = Huffman(mini_text)\n",
    "encoded_message = huffman.encode(mini_text)\n",
    "decoded_message = huffman.decode(encoded_message)\n",
    "assert decoded_message == mini_text\n",
    "\n",
    "# Try LZW\n",
    "lzw = LZW(mini_text)\n",
    "enc_mes = lzw.encode(mini_text)\n",
    "dec_mes = lzw.decode(enc_mes)\n",
    "assert dec_mes == mini_text\n",
    "\n",
    "\n",
    "# Try LZ77\n",
    "lz = LZ77()\n",
    "compressed = lz.compress(mini_text)\n",
    "decompressed = lz.decompress(compressed)\n",
    "assert mini_text == decompressed\n",
    "\n",
    "\n",
    "# Try Deflate\n",
    "# я напишу\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of running time and compression size in percentage of these codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of compress LZ77 with a file size of 98252 characters:  \t1.9682347774505615s\t= 0.0328min.(+-)\n",
      "Time of decompress LZ77 with a file size of 98252 characters:\t0.3560628890991211s\t= 0.00593min.(+-)\n",
      "Percentage of compression LZ77 with a file size of 98252 characters:\t130.45575752641113%\n",
      "\n",
      "Time of compress Huffman with a file size of 98252 characters:  \t0.05984807014465332s\t= 0.001min.(+-)\n",
      "Time of decompress Huffman with a file size of 98252 characters:\t1.77060866355896s\t= 0.02951min.(+-)\n",
      "Percentage of compression Huffman with a file size of 98252 characters:\t42.513536344576295%\n",
      "Time of compress LZW with a file size of 98252 characters:  \t0.1826314926147461s\t= 0.00304min.(+-)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39m# measure the decompression time\u001b[39;00m\n\u001b[0;32m     50\u001b[0m start \u001b[39m=\u001b[39m time()\n\u001b[1;32m---> 51\u001b[0m dec_mes \u001b[39m=\u001b[39m lzw\u001b[39m.\u001b[39;49mdecode(enc_mes)\n\u001b[0;32m     53\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTime of decompress LZW with a file size of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text)\u001b[39m}\u001b[39;00m\u001b[39m characters:\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\\\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[39m{\u001b[39;00mtime() \u001b[39m-\u001b[39m start\u001b[39m}\u001b[39;00m\u001b[39ms\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m= \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39m((time() \u001b[39m-\u001b[39m start)\u001b[39m/\u001b[39m\u001b[39m60\u001b[39m, \u001b[39m5\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39mmin.(+-)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m \u001b[39m# print the percentage of file compression\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 68\u001b[0m, in \u001b[0;36mLZW.decode\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m     65\u001b[0m index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     66\u001b[0m code \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(cod_dict1)\n\u001b[1;32m---> 68\u001b[0m \u001b[39mwhile\u001b[39;00m i \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39;49m(encoded):\n\u001b[0;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mint\u001b[39m(encoded[i]) \u001b[39min\u001b[39;00m cod_dict2:\n\u001b[0;32m     70\u001b[0m         decoded_mes \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m cod_dict2[\u001b[39mint\u001b[39m(encoded[i])]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "lz = LZ77()\n",
    "\n",
    "\n",
    "#__________________Easy_level___________________\n",
    "with open('text1.txt', 'r', encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "\n",
    "#LZ77\n",
    "start = time()\n",
    "compressed = lz.compress(text)\n",
    "print(f\"Time of compress LZ77 with a file size of {len(text)} characters:  \\t{time() - start}s\\t= {round((time() - start)/60, 5)}min.(+-)\")\n",
    "start = time()\n",
    "decompressed = lz.decompress(compressed)\n",
    "print(f\"Time of decompress LZ77 with a file size of {len(text)} characters:\\t{time() - start}s\\t= {round((time() - start)/60, 5)}min.(+-)\")\n",
    "print(f'Percentage of compression LZ77 with a file size of {len(text)} characters:\\t{len(compressed)*(10 + 6 + 8)/len(text.encode())/8*100}%\\n')\n",
    "\n",
    "#Huffman\n",
    "huffman = Huffman(text)\n",
    "# measure the compression time\n",
    "start = time()\n",
    "encoded_message = huffman.encode(text)\n",
    "print(f\"Time of compress Huffman with a file size of {len(text)} characters:  \\t\\\n",
    "{time() - start}s\\t= {round((time() - start)/60, 5)}min.(+-)\")\n",
    "\n",
    "# measure the decompression time\n",
    "start = time()\n",
    "decoded_message = huffman.decode(encoded_message)\n",
    "print(f\"Time of decompress Huffman with a file size of {len(text)} characters:\\t\\\n",
    "{time() - start}s\\t= {round((time() - start)/60, 5)}min.(+-)\")\n",
    "\n",
    "\n",
    "# print the percentage of file compression    \n",
    "compr = (1 - (len(encoded_message) / (len(text.encode(\"utf-8\"))*8))) * 100\n",
    "#  print (f\"compression: {round(compr, 2)}%\")\n",
    "print(f'Percentage of compression Huffman with a file size of {len(text)} characters:\\\n",
    "\\t{compr}%')\n",
    "\n",
    "# LZW\n",
    "\n",
    "lzw = LZW(text)\n",
    "# measure the compression time\n",
    "start = time()\n",
    "enc_mes = lzw.encode(text)\n",
    "print(f\"Time of compress LZW with a file size of {len(text)} characters:  \\t\\\n",
    "{time() - start}s\\t= {round((time() - start)/60, 5)}min.(+-)\")\n",
    "\n",
    "# measure the decompression time\n",
    "start = time()\n",
    "dec_mes = lzw.decode(enc_mes)\n",
    "\n",
    "print(f\"Time of decompress LZW with a file size of {len(text)} characters:\\t\\\n",
    "{time() - start}s\\t= {round((time() - start)/60, 5)}min.(+-)\")\n",
    "\n",
    "# print the percentage of file compression\n",
    "\n",
    "print(f'Percentage of compression LZW with a file size of {len(text)} characters:\\\n",
    "\\t{len(enc_mes)/len(text.encode(\"utf-8\"))*100}%\\n')\n",
    "\n",
    "# print the percentage of file compression\n",
    "\n",
    "print(f'Percentage of LZ77Huffman compression with a file size of {len(text)} characters:\\\n",
    "\\t{len(enc_mes)/len(text.encode(\"utf-8\"))*100}%')\n",
    "#LZ77Huffman\n",
    "LZ77Huffman = LZ77HuffmanEncoder()\n",
    "# measure the compression time\n",
    "start = time()\n",
    "enc_mes = LZ77Huffman.encode(text)\n",
    "print(f\"Time of compress LZ77Huffman with a file size of {len(text)} characters:  \\t\\\n",
    "{time() - start}s\\t= {round((time() - start)/60, 5)}min.(+-)\")\n",
    "\n",
    "# measure the decompression time\n",
    "start = time()\n",
    "dec_mes = LZ77Huffman.decode(enc_mes)\n",
    "\n",
    "print(f\"Time of decompress LZ77Huffman with a file size of {len(text)} characters:\\t\\\n",
    "{time() - start}s\\t= {round((time() - start)/60, 5)}min.(+-)\")\n",
    "\n",
    "# print the percentage of file compression\n",
    "\n",
    "print(f'Percentage of compression LZ77Huffman with a file size of {len(text)} characters:\\\n",
    "\\t{len(enc_mes)/len(text.encode(\"utf-8\"))*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of compress LZ77 with a file size of 528474 characters:  \t4.828818321228027s\t= 0.08048min.(+-)\n",
      "Time of decompress LZ77 with a file size of 528474 characters:\t6.9122865200042725s\t= 0.1152min.(+-)\n",
      "Percentage of compression LZ77 with a file size of 528474 characters:\t123.99487045080126%\n",
      "\n",
      "Time of compress Huffman with a file size of 528474 characters:  \t0.42104387283325195s\t= 0.00702min.(+-)\n"
     ]
    }
   ],
   "source": [
    "# _________________Medium_level____________________\n",
    "with open('text2.txt', 'r', encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "#напиши Гафмана\n",
    "# Напиши LZW\n",
    "#LZ77\n",
    "start = time()\n",
    "compressed = lz.compress(text)\n",
    "print(f\"Time of compress LZ77 with a file size of {len(text)} characters:  \\t{time() - start}s\\t= {round((time() - start)/60, 5)}min.(+-)\")\n",
    "start = time()\n",
    "decompressed = lz.decompress(compressed)\n",
    "print(f\"Time of decompress LZ77 with a file size of {len(text)} characters:\\t{time() - start}s\\t= {round((time() - start)/60, 5)}min.(+-)\")\n",
    "print(f'Percentage of compression LZ77 with a file size of {len(text)} characters:\\t{len(compressed)*(10 + 6 + 8)/len(text.encode())/8*100}%\\n')\n",
    "\n",
    "#Huffman\n",
    "huffman = Huffman(text)\n",
    "# measure the compression time\n",
    "start = time()\n",
    "encoded_message = huffman.encode(text)\n",
    "print(f\"Time of compress Huffman with a file size of {len(text)} characters:  \\t\\\n",
    "{time() - start}s\\t= {round((time() - start)/60, 5)}min.(+-)\")\n",
    "\n",
    "# measure the decompression time\n",
    "start = time()\n",
    "decoded_message = huffman.decode(encoded_message)\n",
    "print(f\"Time of decompress Huffman with a file size of {len(text)} characters:\\t\\\n",
    "{time() - start}s\\t= {round((time() - start)/60, 5)}min.(+-)\")\n",
    "\n",
    "\n",
    "# print the percentage of file compression    \n",
    "compr = (1 - (len(encoded_message) / (len(text.encode(\"utf-8\"))*8))) * 100\n",
    "#  print (f\"compression: {round(compr, 2)}%\")\n",
    "print(f'Percentage of compression Huffman with a file size of {len(text)} characters:\\\n",
    "\\t{compr}%')\n",
    "\n",
    "# LZW\n",
    "\n",
    "lzw = LZW(text)\n",
    "# measure the compression time\n",
    "start = time()\n",
    "enc_mes = lzw.encode(text)\n",
    "print(f\"Time of compress LZW with a file size of {len(text)} characters:  \\t\\\n",
    "{time() - start}s\\t= {round((time() - start)/60, 5)}min.(+-)\")\n",
    "\n",
    "# measure the decompression time\n",
    "start = time()\n",
    "dec_mes = lzw.decode(enc_mes)\n",
    "\n",
    "print(f\"Time of decompress LZW with a file size of {len(text)} characters:\\t\\\n",
    "{time() - start}s\\t= {round((time() - start)/60, 5)}min.(+-)\")\n",
    "\n",
    "# print the percentage of file compression\n",
    "\n",
    "print(f'Percentage of compression LZW with a file size of {len(text)} characters:\\\n",
    "\\t{len(enc_mes)/len(text.encode(\"utf-8\"))*100}%')\n",
    "\n",
    "#LZ77Huffman\n",
    "LZ77Huffman = LZ77HuffmanEncoder()\n",
    "# measure the compression time\n",
    "start = time()\n",
    "enc_mes = LZ77Huffman.encode(text)\n",
    "print(f\"Time of compress LZ77Huffman with a file size of {len(text)} characters:  \\t\\\n",
    "{time() - start}s\\t= {round((time() - start)/60, 5)}min.(+-)\")\n",
    "\n",
    "# measure the decompression time\n",
    "start = time()\n",
    "dec_mes = LZ77Huffman.decode(enc_mes)\n",
    "\n",
    "print(f\"Time of decompress LZ77Huffman with a file size of {len(text)} characters:\\t\\\n",
    "{time() - start}s\\t= {round((time() - start)/60, 5)}min.(+-)\")\n",
    "\n",
    "# print the percentage of file compression\n",
    "\n",
    "print(f'Percentage of compression LZ77Huffman with a file size of {len(text)} characters:\\\n",
    "\\t{len(enc_mes)/len(text.encode(\"utf-8\"))*100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
